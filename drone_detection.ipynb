{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 1 — Imports\n",
    "import os, time, math, glob, random\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 2 — Config\n",
    "DATASET_YAML = r\"S:\\IntelliJ\\Projects\\ES_Drone_Detection\\datasets\\drone_mixed.yaml\"   # adjust if your yaml has different name\n",
    "SPLIT = \"test\"  # \"val\" or \"test\"\n",
    "IMGSZ = (640, 384)  # (w, h) to match your common 640x384 inference\n",
    "CONF = 0.25\n",
    "IOU_NMS = 0.7\n",
    "MAX_IMAGES = 3000   # set None to run full split; start with 500-3000 for iteration\n",
    "\n",
    "# Your trained model path (edit to your actual best.pt)\n",
    "MODEL_WEIGHTS = r\"S:\\IntelliJ\\Projects\\ES_Drone_Detection\\runs\\detect\\yolo11\\drone_finetune_full_mixed4\\weights\\best.pt\"\n",
    "\n",
    "# If your model was initialized from drone weights but you only have 1 class, keep it as-is.\n",
    "# If you have multiple classes (e.g., drone/bird), the evaluator below supports multiple labels too.\n"
   ],
   "id": "fd9db2a404d248f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 3 — Helpers: read YOLO yaml + resolve split paths\n",
    "import yaml\n",
    "\n",
    "def load_data_yaml(yaml_path):\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        y = yaml.safe_load(f)\n",
    "    return y\n",
    "\n",
    "def resolve_split_images(data_yaml, split):\n",
    "    # Ultralytics yaml may store train/val/test as relative paths\n",
    "    base = Path(DATASET_YAML).parent\n",
    "    split_key = split\n",
    "    if split_key not in data_yaml:\n",
    "        raise ValueError(f\"Split '{split}' not found in data.yaml keys: {list(data_yaml.keys())}\")\n",
    "    split_path = data_yaml[split_key]\n",
    "    split_path = (base / split_path).resolve() if not os.path.isabs(split_path) else Path(split_path)\n",
    "\n",
    "    # Common YOLO layouts: images under split_path, or split_path itself is a txt list\n",
    "    if split_path.suffix.lower() == \".txt\":\n",
    "        with open(split_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            imgs = [line.strip() for line in f if line.strip()]\n",
    "        return imgs\n",
    "    else:\n",
    "        exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.webp\")\n",
    "        imgs = []\n",
    "        for e in exts:\n",
    "            imgs.extend(glob.glob(str(split_path / \"**\" / e), recursive=True))\n",
    "        imgs = sorted(imgs)\n",
    "        return imgs\n",
    "\n",
    "data_yaml = load_data_yaml(DATASET_YAML)\n",
    "img_paths = resolve_split_images(data_yaml, SPLIT)\n",
    "\n",
    "if MAX_IMAGES is not None:\n",
    "    img_paths = img_paths[:MAX_IMAGES]\n",
    "\n",
    "len(img_paths), img_paths[0]\n"
   ],
   "id": "eca30fd942be7e00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 4 — Label IO (YOLO txt)\n",
    "def image_to_label_path(img_path):\n",
    "    # standard: .../images/... -> .../labels/... and .jpg -> .txt\n",
    "    p = Path(img_path)\n",
    "    parts = list(p.parts)\n",
    "    # Replace 'images' folder with 'labels' if present\n",
    "    if \"images\" in parts:\n",
    "        parts[parts.index(\"images\")] = \"labels\"\n",
    "    label_path = Path(*parts).with_suffix(\".txt\")\n",
    "    return str(label_path)\n",
    "\n",
    "def load_yolo_labels(label_path, img_w, img_h):\n",
    "    # returns list of (cls, x1, y1, x2, y2) in pixel coords\n",
    "    if not os.path.exists(label_path):\n",
    "        return []\n",
    "    out = []\n",
    "    with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            cls, xc, yc, w, h = line.split()\n",
    "            cls = int(float(cls))\n",
    "            xc, yc, w, h = map(float, (xc, yc, w, h))\n",
    "            x1 = (xc - w/2) * img_w\n",
    "            y1 = (yc - h/2) * img_h\n",
    "            x2 = (xc + w/2) * img_w\n",
    "            y2 = (yc + h/2) * img_h\n",
    "            out.append((cls, x1, y1, x2, y2))\n",
    "    return out\n",
    "\n",
    "def box_iou(a, b):\n",
    "    # a,b: (x1,y1,x2,y2)\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "    iw = max(0.0, inter_x2 - inter_x1)\n",
    "    ih = max(0.0, inter_y2 - inter_y1)\n",
    "    inter = iw * ih\n",
    "    area_a = max(0.0, ax2-ax1) * max(0.0, ay2-ay1)\n",
    "    area_b = max(0.0, bx2-bx1) * max(0.0, by2-by1)\n",
    "    union = area_a + area_b - inter + 1e-9\n",
    "    return inter / union\n"
   ],
   "id": "17cbbabb77a72fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 5 — Preprocessing functions (moving-camera-safe)\n",
    "def to_ycrcb_clahe(bgr, clip_limit=2.0, tile_grid=(8,8)):\n",
    "    ycrcb = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)\n",
    "    y2 = clahe.apply(y)\n",
    "    out = cv2.merge([y2, cr, cb])\n",
    "    return cv2.cvtColor(out, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "def gray_world_wb(bgr):\n",
    "    # Simple gray-world white balance\n",
    "    b, g, r = cv2.split(bgr.astype(np.float32))\n",
    "    mb, mg, mr = b.mean(), g.mean(), r.mean()\n",
    "    m = (mb + mg + mr) / 3.0\n",
    "    b *= (m / (mb + 1e-6))\n",
    "    g *= (m / (mg + 1e-6))\n",
    "    r *= (m / (mr + 1e-6))\n",
    "    out = cv2.merge([b, g, r])\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "def unsharp_mask(bgr, amount=0.6, blur_ksize=3):\n",
    "    # Mild sharpening\n",
    "    blur = cv2.GaussianBlur(bgr, (blur_ksize, blur_ksize), 0)\n",
    "    sharp = cv2.addWeighted(bgr, 1.0 + amount, blur, -amount, 0)\n",
    "    return sharp\n",
    "\n",
    "def light_bilateral(bgr, d=5, sigma_color=40, sigma_space=40):\n",
    "    # Edge-preserving denoise; keep small for speed\n",
    "    return cv2.bilateralFilter(bgr, d=d, sigmaColor=sigma_color, sigmaSpace=sigma_space)\n",
    "\n",
    "def preprocess_pipeline(name, bgr):\n",
    "    # Compose a few curated pipelines\n",
    "    if name == \"baseline\":\n",
    "        return bgr\n",
    "    if name == \"clahe_y\":\n",
    "        return to_ycrcb_clahe(bgr, clip_limit=2.0, tile_grid=(8,8))\n",
    "    if name == \"clahe_y + unsharp\":\n",
    "        x = to_ycrcb_clahe(bgr, clip_limit=2.0, tile_grid=(8,8))\n",
    "        return unsharp_mask(x, amount=0.5, blur_ksize=3)\n",
    "    if name == \"wb + clahe_y\":\n",
    "        x = gray_world_wb(bgr)\n",
    "        return to_ycrcb_clahe(x, clip_limit=2.0, tile_grid=(8,8))\n",
    "    if name == \"clahe_y + bilateral + unsharp\":\n",
    "        x = to_ycrcb_clahe(bgr, clip_limit=2.0, tile_grid=(8,8))\n",
    "        x = light_bilateral(x, d=5, sigma_color=35, sigma_space=35)\n",
    "        return unsharp_mask(x, amount=0.4, blur_ksize=3)\n",
    "    raise ValueError(f\"Unknown pipeline: {name}\")\n",
    "\n",
    "PIPELINES = [\n",
    "    \"baseline\",\n",
    "    \"clahe_y\",\n",
    "    \"clahe_y + unsharp\",\n",
    "    \"wb + clahe_y\",\n",
    "    \"clahe_y + bilateral + unsharp\",\n",
    "]\n"
   ],
   "id": "495f8b43cdbbe254"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 6 — Model load\n",
    "model = YOLO(MODEL_WEIGHTS)\n"
   ],
   "id": "97a89cd38755351d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 7 — Inference + evaluation loop\n",
    "def match_detections_to_gt(pred_boxes, gt_boxes, iou_thr=0.5):\n",
    "    \"\"\"\n",
    "    pred_boxes: list of (cls, conf, x1,y1,x2,y2)\n",
    "    gt_boxes:   list of (cls, x1,y1,x2,y2)\n",
    "    Greedy matching by highest IoU per prediction.\n",
    "    \"\"\"\n",
    "    gt_used = [False]*len(gt_boxes)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    ious = []\n",
    "\n",
    "    # Sort preds by confidence desc\n",
    "    pred_boxes = sorted(pred_boxes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for p in pred_boxes:\n",
    "        pcls, conf, px1, py1, px2, py2 = p\n",
    "        best_iou = 0\n",
    "        best_j = -1\n",
    "        for j, g in enumerate(gt_boxes):\n",
    "            if gt_used[j]:\n",
    "                continue\n",
    "            gcls, gx1, gy1, gx2, gy2 = g\n",
    "            if pcls != gcls:\n",
    "                continue\n",
    "            iou = box_iou((px1,py1,px2,py2), (gx1,gy1,gx2,gy2))\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_j = j\n",
    "        if best_iou >= iou_thr and best_j >= 0:\n",
    "            gt_used[best_j] = True\n",
    "            tp += 1\n",
    "            ious.append(best_iou)\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    fn = sum(1 for u in gt_used if not u)\n",
    "    return tp, fp, fn, ious\n",
    "\n",
    "def run_experiment(pipeline_name):\n",
    "    t0 = time.perf_counter()\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    all_ious = []\n",
    "\n",
    "    # FPS timing includes: read + preprocess + inference + post\n",
    "    for img_path in img_paths:\n",
    "        bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if bgr is None:\n",
    "            continue\n",
    "\n",
    "        # preprocess\n",
    "        bgr2 = preprocess_pipeline(pipeline_name, bgr)\n",
    "\n",
    "        # YOLO inference (Ultralytics accepts numpy BGR)\n",
    "        results = model.predict(\n",
    "            source=bgr2,\n",
    "            imgsz=list(IMGSZ)[::-1],  # Ultralytics expects (h,w) sometimes; keep consistent\n",
    "            conf=CONF,\n",
    "            iou=IOU_NMS,\n",
    "            verbose=False,\n",
    "            device=0  # GPU if available\n",
    "        )\n",
    "\n",
    "        # Extract predictions\n",
    "        r0 = results[0]\n",
    "        pred_boxes = []\n",
    "        if r0.boxes is not None and len(r0.boxes) > 0:\n",
    "            xyxy = r0.boxes.xyxy.cpu().numpy()\n",
    "            confs = r0.boxes.conf.cpu().numpy()\n",
    "            clss  = r0.boxes.cls.cpu().numpy().astype(int)\n",
    "            for (x1,y1,x2,y2), c, k in zip(xyxy, confs, clss):\n",
    "                pred_boxes.append((int(k), float(c), float(x1), float(y1), float(x2), float(y2)))\n",
    "\n",
    "        # Ground truth\n",
    "        h, w = bgr.shape[:2]\n",
    "        gt = load_yolo_labels(image_to_label_path(img_path), w, h)\n",
    "\n",
    "        # Match @ IoU 0.5\n",
    "        tp, fp, fn, ious = match_detections_to_gt(pred_boxes, gt, iou_thr=0.5)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        all_ious.extend(ious)\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    secs = max(1e-9, t1 - t0)\n",
    "    n = len(img_paths)\n",
    "    fps = n / secs\n",
    "\n",
    "    precision = total_tp / (total_tp + total_fp + 1e-9)\n",
    "    recall    = total_tp / (total_tp + total_fn + 1e-9)\n",
    "    f1        = 2*precision*recall / (precision + recall + 1e-9)\n",
    "    miou      = float(np.mean(all_ious)) if all_ious else 0.0\n",
    "\n",
    "    return {\n",
    "        \"pipeline\": pipeline_name,\n",
    "        \"images\": n,\n",
    "        \"tp\": total_tp,\n",
    "        \"fp\": total_fp,\n",
    "        \"fn\": total_fn,\n",
    "        \"precision@0.5\": precision,\n",
    "        \"recall@0.5\": recall,\n",
    "        \"f1@0.5\": f1,\n",
    "        \"mean_iou(tp)\": miou,\n",
    "        \"fps_e2e\": fps,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for p in PIPELINES:\n",
    "    print(\"Running:\", p)\n",
    "    rows.append(run_experiment(p))\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(by=[\"f1@0.5\", \"fps_e2e\"], ascending=False)\n",
    "df\n"
   ],
   "id": "1200ddaf6707d055"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 8 — Quick qualitative visualization (side-by-side)\n",
    "def draw_boxes(img, boxes, color=(0,255,0), label_prefix=\"P\"):\n",
    "    out = img.copy()\n",
    "    for b in boxes:\n",
    "        if len(b) == 6:  # pred (cls, conf, x1,y1,x2,y2)\n",
    "            cls, conf, x1,y1,x2,y2 = b\n",
    "            txt = f\"{label_prefix}:{cls} {conf:.2f}\"\n",
    "        else:            # gt (cls, x1,y1,x2,y2)\n",
    "            cls, x1,y1,x2,y2 = b\n",
    "            txt = f\"GT:{cls}\"\n",
    "        x1,y1,x2,y2 = map(int, [x1,y1,x2,y2])\n",
    "        cv2.rectangle(out, (x1,y1), (x2,y2), color, 2)\n",
    "        cv2.putText(out, txt, (x1, max(0,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
    "    return out\n",
    "\n",
    "def sample_and_show(pipeline_name, k=6, seed=0):\n",
    "    random.seed(seed)\n",
    "    picks = random.sample(img_paths, k=min(k, len(img_paths)))\n",
    "\n",
    "    for img_path in picks:\n",
    "        bgr = cv2.imread(img_path)\n",
    "        bgr2 = preprocess_pipeline(pipeline_name, bgr)\n",
    "\n",
    "        res = model.predict(source=bgr2, imgsz=list(IMGSZ)[::-1], conf=CONF, iou=IOU_NMS, verbose=False, device=0)[0]\n",
    "        pred = []\n",
    "        if res.boxes is not None and len(res.boxes) > 0:\n",
    "            xyxy = res.boxes.xyxy.cpu().numpy()\n",
    "            confs = res.boxes.conf.cpu().numpy()\n",
    "            clss  = res.boxes.cls.cpu().numpy().astype(int)\n",
    "            for (x1,y1,x2,y2), c, kcls in zip(xyxy, confs, clss):\n",
    "                pred.append((int(kcls), float(c), float(x1), float(y1), float(x2), float(y2)))\n",
    "\n",
    "        h, w = bgr.shape[:2]\n",
    "        gt = load_yolo_labels(image_to_label_path(img_path), w, h)\n",
    "\n",
    "        vis0 = draw_boxes(bgr, gt, color=(255,255,0), label_prefix=\"\")   # GT\n",
    "        vis1 = draw_boxes(bgr2, pred, color=(0,255,0), label_prefix=\"P\") # Pred on preprocessed\n",
    "\n",
    "        stacked = np.hstack([\n",
    "            cv2.resize(vis0, (640, 384)),\n",
    "            cv2.resize(vis1, (640, 384)),\n",
    "        ])\n",
    "        cv2.imshow(f\"{pipeline_name} | Left: GT, Right: Pred (preprocessed)\", stacked)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "1213fbc5f0e0e9ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example:\n",
    "sample_and_show(\"clahe_y + unsharp\", k=10, seed=42)\n"
   ],
   "id": "998fdfa80959072c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
